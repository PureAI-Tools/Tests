{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dtgLxkQBVU4",
        "outputId": "6b4302f6-0069-42e5-8887-3b47b613f422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: purecpp_extract in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: purecpp_chunks_clean in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: purecpp_libs in /usr/local/lib/python3.11/dist-packages (from purecpp_extract) (0.0.3)\n",
            "Requirement already satisfied: auditwheel in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (6.3.0)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (1.2.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (2.32.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (0.45.1)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (2.13.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from purecpp_chunks_clean) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from auditwheel->purecpp_chunks_clean) (24.2)\n",
            "Requirement already satisfied: pyelftools>=0.24 in /usr/local/lib/python3.11/dist-packages (from auditwheel->purecpp_chunks_clean) (0.32)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build->purecpp_chunks_clean) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->purecpp_chunks_clean) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->purecpp_chunks_clean) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->purecpp_chunks_clean) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->purecpp_chunks_clean) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install purecpp_extract purecpp_chunks_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id24_ARrT_KY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PureAI-Tools/Tests.git\n",
        "API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TAd_tzUZBVU5"
      },
      "outputs": [],
      "source": [
        "import purecpp_extract as ext\n",
        "import purecpp_chunks_clean as cc\n",
        "from purecpp_libs import DataExtractRequestStruct, LoaderDataStruct, RAGDocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UZD-yrgDBVU5"
      },
      "outputs": [],
      "source": [
        "pdf_loader = ext.PDFLoader()\n",
        "pdf_loader2 = ext.PDFLoader()\n",
        "pdf_loader3 = ext.PDFLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bQJYoK9vBVU5"
      },
      "outputs": [],
      "source": [
        "docxLoader = ext.DOCXLoader()\n",
        "docxLoader2 = ext.DOCXLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hetDV2BWBVU5",
        "outputId": "98784087-4e9f-480d-f275-030e0949d007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "var = pdf_loader.InsertDataToExtract([\n",
        "        DataExtractRequestStruct(\"/content/Tests/pdfs/1984.pdf\"),\n",
        "        DataExtractRequestStruct(\"/content/Tests/pdfs/a-christmas-carol.pdf\"),\n",
        "    ]) # No jupiter ta imprimindo q tao sendo achados arquivos aqui n\n",
        "print(var) # Poderia..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zDJhPHARBVU6"
      },
      "outputs": [],
      "source": [
        "# pdf_loader2.InsertDataToExtract([DataExtractRequestStruct(\"pdfs\")]) # deveria dar erro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSTt3r20BVU6"
      },
      "outputs": [],
      "source": [
        "pdf_loader3.InsertDataToExtract([DataExtractRequestStruct(\"Tests/pdfs/1984.pdf\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1VwPoL0BVU6"
      },
      "outputs": [],
      "source": [
        "docxLoader.InsertDataToExtract([\n",
        "        DataExtractRequestStruct(\"Tests/docxs/sample1.docx\"),\n",
        "        DataExtractRequestStruct(\"Tests/docxs/sample4.docx\")\n",
        "    ]) # Tem que avisar que n encontra a pasta ou o arquivo na pasta se n o encontrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rydW1EdIBVU6"
      },
      "outputs": [],
      "source": [
        "docxLoader2.InsertDataToExtract([DataExtractRequestStruct(\"docxs\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3NCE2x2BVU6",
        "outputId": "3cbbc2ae-3545-4648-dc24-6646af1f800b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Download free eBooks of classic literature, books and \\r\\nnovels at Planet eBook. Subscribe to our free eBooks blog \\r\\nand email newsletter.\\r\\n1984\\r\\nBy George Orwell']\n",
            "\n",
            "\n",
            "['\\x18 1984\\r\\nPart One']\n",
            "\n",
            "\n",
            "['Free eBooks at Planet eBook.com \\x18\\r\\nChapter 1\\r\\nI\\r\\nt was a bright cold day in April, and the clocks were strik\\x02ing thirteen. Winston Smith, his chin nuzzled into his \\r\\nbreast in an effort to escape the vile wind, slipped quickly \\r\\nthrough the glass doors of Victory Mansions, though not \\r\\nquickly enough to prevent a swirl of gritty dust from enter\\x02ing along with him.\\r\\nThe hallway smelt of boiled cabbage and old rag mats. At \\r\\none end of it a coloured poster, too large for indoor display, \\r\\nhad been tacked to the wall. It depicted simply an enor\\x02mous face, more than a metre wide: the face of a man of \\r\\nabout forty-five, with a heavy black moustache and rugged\\x02ly handsome features. Winston made for the stairs. It was \\r\\nno use trying the lift. Even at the best of times it was sel\\x02dom working, and at present the electric current was cut \\r\\noff during daylight hours. It was part of the economy drive \\r\\nin preparation for Hate Week. The flat was seven flights up, \\r\\nand Winston, who was thirty-nine and had a varicose ulcer \\r\\nabove his right ankle, went slowly, resting several times on \\r\\nthe way. On each landing, opposite the lift-shaft, the poster \\r\\nwith the enormous face gazed from the wall. It was one of \\r\\nthose pictures which are so contrived that the eyes follow \\r\\nyou about when you move. BIG BROTHER IS WATCHING \\r\\nYOU, the caption beneath it ran.\\r\\nInside the flat a fruity voice was reading out a list of fig-']\n",
            "\n",
            "\n",
            "393 Pages\n"
          ]
        }
      ],
      "source": [
        "opt_struct = pdf_loader.GetTextContent(\"1984\") # N retorna um tipo string\n",
        "text_content = str(opt_struct)\n",
        "text_content_limited = text_content[:100]\n",
        "# print(text_content_limited)\n",
        "for i in range(3):\n",
        "  print(opt_struct.textContent[i:i+1])\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(f\"{len(opt_struct.textContent)} Pages\")# Isso salva como paginas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK4ChA8zIlvA",
        "outputId": "48ef59d7-0d0d-419f-aaa6-41b4da452b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'purecpp_libs.purecpp_libs.LoaderDataStruct'>\n",
            "__class__\n",
            "__delattr__\n",
            "__dir__\n",
            "__doc__\n",
            "__eq__\n",
            "__format__\n",
            "__ge__\n",
            "__getattribute__\n",
            "__getstate__\n",
            "__gt__\n",
            "__hash__\n",
            "__init__\n",
            "__init_subclass__\n",
            "__le__\n",
            "__lt__\n",
            "__module__\n",
            "__ne__\n",
            "__new__\n",
            "__reduce__\n",
            "__reduce_ex__\n",
            "__repr__\n",
            "__setattr__\n",
            "__sizeof__\n",
            "__str__\n",
            "__subclasshook__\n",
            "_pybind11_conduit_v1_\n",
            "metadata\n",
            "textContent\n",
            "<class 'list'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(type(opt_struct))\n",
        "for item in dir(opt_struct):\n",
        "    print(item)\n",
        "print(type(dir(opt_struct)))\n",
        "# help(opt_struct)\n",
        "type(opt_struct.textContent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv67-1GGJAu0",
        "outputId": "5321a39a-84f9-4c5a-8028-c5d7f90b5bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_pybind11_conduit_v1_: <bound method PyCapsule._pybind11_conduit_v1_ of <purecpp_libs.purecpp_libs.LoaderDataStruct object at 0x7d59d0632330>>\n",
            "----------------------------------------------\n",
            "metadata: {'fileIdentifier': 'a-christmas-carol'}\n",
            "----------------------------------------------\n",
            "textContent: Is a list of 106 Pages\n",
            "Page 0 textContent :\n",
            "Download free eBooks of classic literature, books and \r\n",
            "novels at Planet eBook. Subscribe to our free eBooks blog \r\n",
            "and email newsletter.\r\n",
            "A Christmas Carol\r\n",
            "By Charles Dickens \n",
            "----------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for attr_name in dir(opt_struct):\n",
        "    if not attr_name.startswith(\"__\"):  # Ignora atributos internos\n",
        "        try:\n",
        "            value = getattr(opt_struct, attr_name)\n",
        "            if attr_name == \"textContent\":\n",
        "                print(f\"{attr_name}: Is a list of {len(value)} Pages\")\n",
        "                print(f\"Page 0 {attr_name} :\\n{value[0]} \")\n",
        "            else:\n",
        "              print(f\"{attr_name}: {value}\")\n",
        "            print(\"----------------------------------------------\")\n",
        "        except AttributeError:\n",
        "            print(f\"{attr_name}: [não acessível]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6UQu19NBVU6",
        "outputId": "66540bd6-206c-4f77-8ba4-1e93284e8c0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<purecpp_libs.purecpp_libs.LoaderDataStruct at 0x7d59d0633c70>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_loader.GetTextContent(\"1984\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPEMKujoOspw",
        "outputId": "c9b9674d-76a0-41ad-f995-e097041de9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deu erro\n"
          ]
        }
      ],
      "source": [
        "if not pdf_loader3.GetTextContent(\"a-christmas-carol\"): # DEVERIA DAR ERRO\n",
        "    print(\"deu erro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9QBx5UpKBVU7"
      },
      "outputs": [],
      "source": [
        "pdf_loader3.GetTextContent(\"sdauhdsahudsauhdsahuds\") # DEVERIA DAR ERRO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mfJHH8uJP84r"
      },
      "outputs": [],
      "source": [
        "# print(type(pdf_loader))\n",
        "# for item in dir(pdf_loader):\n",
        "#     print(item)\n",
        "# print(type(dir(pdf_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bxGLAn7iSqOi"
      },
      "outputs": [],
      "source": [
        "# help(pdf_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5b8RLZ8BVU7",
        "outputId": "0c420109-123b-4b20-fb52-d533e06b3599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de documentos carregados: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items_docx = []\n",
        "\n",
        "for fname in [\"sample1\", \"sample4\"]: # poderia ter um metodo para recuperar as listas naquela List de LoaderDataStruct < --------------- >\n",
        "    x = docxLoader.GetTextContent(fname)\n",
        "    if x:\n",
        "        items_docx.append(x.textContent)  # cada item é um List em LoaderDataStruct\n",
        "    else:\n",
        "        print(f\"Não foi possível extrair: {fname}\")\n",
        "if not items_docx:\n",
        "        print(\"Nenhum documento foi carregado com sucesso! Encerrando.\")\n",
        "print(f\"Total de documentos carregados: {len(items_docx)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRrzy5w2BVU7",
        "outputId": "d9c7d506-b274-4798-acf6-c10dc474c0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de documentos carregados: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items = []\n",
        "item_struct =  []\n",
        "\n",
        "for fname in [\"1984\", \"a-christmas-carol\"]: # poderia ter um metodo para recuperar as listas naquela List de LoaderDataStruct < --------------- >\n",
        "    opt_struct = pdf_loader.GetTextContent(fname)\n",
        "    if opt_struct:\n",
        "        items.append(opt_struct.textContent)   # cada item é um List em LoaderDataStruct\n",
        "        item_struct.append(opt_struct) # cada item é LoaderDataStruct\n",
        "    else:\n",
        "        print(f\"Não foi possível extrair: {fname}\")\n",
        "if not items:\n",
        "        print(\"Nenhum documento foi carregado com sucesso! Encerrando.\")\n",
        "print(f\"Total de documentos carregados: {len(items)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWxrWtxABVU7",
        "outputId": "89a8b0c8-45c6-43e8-9f0a-19c4aaa3adf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "--- LoaderDataStruct nº 0 ---\n",
            ">> METADATA:\n",
            "   fileIdentifier => 1984\n",
            "\n",
            ">> TEXT CONTENT=> Free eBooks at Planet eBook.com 11\r\n",
            "er of expressing himself, but even to have forgotten what it \r\n",
            "w ...\n",
            "\n",
            "--- LoaderDataStruct nº 1 ---\n",
            ">> METADATA:\n",
            "   fileIdentifier => a-christmas-carol\n",
            "\n",
            ">> TEXT CONTENT=> Free eBooks at Planet eBook.com 11\r\n",
            "‘Under the impression that they scarcely furnish Chris\u0002tian chee ...\n",
            "\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# item_struct n es interavel < --------------- >\n",
        "# for i, item in enumerate(item_struct):\n",
        "#     print(f\"------------- Item {i} ------------- \")\n",
        "#     for j, key in enumerate(item):\n",
        "#         print(f\"Índice={j}, Chave='{key}' => Valor='{item[key]}'\")\n",
        "# Agora imprimir em \"item_struct\", que é uma lista de LoaderDataStruct\n",
        "\n",
        "print(\"---------------------------------------------------------\")\n",
        "for i, lds in enumerate(item_struct):\n",
        "    print(f\"--- LoaderDataStruct nº {i} ---\")\n",
        "\n",
        "    print(\">> METADATA:\")\n",
        "    for mk, mv in lds.metadata.items():\n",
        "        print(f\"   {mk} => {mv}\")\n",
        "\n",
        "    print(f\"\\n>> TEXT CONTENT=> {lds.textContent[10][:100]} ...\")\n",
        "    print()\n",
        "print(\"---------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FULkiChjBVU7"
      },
      "outputs": [],
      "source": [
        "# 2) CHUNKANDO COM ChunkDefault\n",
        "#    (divide texto em blocos de 300 chars, com overlap=50)\n",
        "# default_chunker = cc.ChunkDefault(chunk_size=300, overlap=50)\n",
        "default_chunker = cc.ChunkDefault(300, 50) # poderia passar o item ja aqui\n",
        "default_chunker2 = cc.ChunkDefault(300, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wAFR3RUpBVU7"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessSingleDocument(RAGLibrary::LoaderDataStruct &item);\n",
        "\n",
        "default_docs = default_chunker.ProcessSingleDocument(item_struct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wmHqE8EpMu1s"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessDocuments(const std::vector<RAGLibrary::LoaderDataStruct> &items, int max_workers = 4);\n",
        "\n",
        "# default_docs2 = default_chunker2.ProcessDocuments(item_struct[0], max_workers=2)\n",
        "# --------- ERRO\n",
        "# TypeError: ProcessDocuments(): incompatible function arguments. The following argument types are supported:\n",
        "#     1. (self: purecpp_chunks_clean.purecpp_chunks_clean.ChunkDefault, items: list[RAGLibrary::LoaderDataStruct], max_workers: int = 4) -> list[RAGLibrary::Document]\n",
        "\n",
        "# Invoked with: <purecpp_chunks_clean.purecpp_chunks_clean.ChunkDefault object at 0x7f8b74117bb0>, <purecpp_libs.purecpp_libs.LoaderDataStruct object at 0x7f8b75d467f0>; kwargs: max_workers=2\n",
        "\n",
        "default_docs2 = default_chunker2.ProcessDocuments(item_struct, max_workers=2) # Tem q ser uma lista de purecpp_libs.purecpp_libs.LoaderDataStruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjA8yE8jBVU8",
        "outputId": "cf4f33dd-ac4c-4fd4-82a2-a8991c17e358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChunkDefault(300, 50) from '1984': documents.size=2479\n"
          ]
        }
      ],
      "source": [
        "print(f\"ChunkDefault(300, 50) from '{item_struct[0].metadata['fileIdentifier']}': documents.size={len(default_docs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HoWsUFLqNFWQ"
      },
      "outputs": [],
      "source": [
        "# print(type(default_docs))\n",
        "# for item in dir(default_docs):\n",
        "#     print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "t5xFhnxuNoh3"
      },
      "outputs": [],
      "source": [
        "# help(default_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iduy2eP_OHqY"
      },
      "outputs": [],
      "source": [
        "# print(type(default_docs[0])) # purecpp_libs.purecpp_libs.RAGDocument\n",
        "# for item in dir(default_docs[0]):\n",
        "#     print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "x-uKKkg8Sw6E"
      },
      "outputs": [],
      "source": [
        "# type(default_docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "STSz0CSLOg_c"
      },
      "outputs": [],
      "source": [
        "# default_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ily7TuhZBVU8",
        "outputId": "617a780f-0eeb-40fb-868b-8d58cc56f175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo de chunk gerado (primeiro):\n",
            "  METADATA: {'fileIdentifier': '1984'}\n",
            "  CHUNK (trecho): Download free eBooks of classic literature, books and \r\n",
            "novels at Planet eBook. Subscribe to our free eBooks blog \r\n",
            "and email newsletter.\r\n",
            "1984\r\n",
            "By Ge ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Exemplo: imprimir um snippet do primeiro chunk\n",
        "if default_docs:\n",
        "    print(\"Exemplo de chunk gerado (primeiro):\")\n",
        "    print(\"  METADATA:\", default_docs[0].metadata)\n",
        "    print(\"  CHUNK (trecho):\", default_docs[0].page_content[:150], \"...\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "A03Dp40tBVU8"
      },
      "outputs": [],
      "source": [
        "# for i, doc in enumerate(default_docs):\n",
        "#     if i > 10: break\n",
        "#     print(f\"{i}:  {doc.StringRepr()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sgjq5f5LS-dI"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TC3FnO6STE3s"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bTQoEHv-BVU8"
      },
      "outputs": [],
      "source": [
        "# 3) CHUNKANDO COM ChunkCount (divide texto a cada pontuação final, usando regex, overlap menor)\n",
        "# ChunkCount(const std::string &count_unit, const int overlap = 600, const int count_threshold = 1);\n",
        "count_chunker = cc.ChunkCount(\"regex:[.!?]+\", overlap=10, count_threshold=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2SeCahSTBVU8"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessSingleDocument(RAGLibrary::LoaderDataStruct &item);\n",
        "\n",
        "count_docs = count_chunker.ProcessSingleDocument(item_struct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PD1i56dFS5Vc"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessDocuments(const std::vector<RAGLibrary::LoaderDataStruct> &items, int max_workers = 4);\n",
        "\n",
        "# count_docs2 = count_chunker.ProcessDocuments(item_struct[0], max_workers=2)\n",
        "# ---------------- ERRO\n",
        "# TypeError                                 Traceback (most recent call last)\n",
        "# Cell In[33], line 2\n",
        "#       1 # std::vector<RAGLibrary::Document> ProcessDocuments(const std::vector<RAGLibrary::LoaderDataStruct> &items, int max_workers = 4);\n",
        "# ----> 2 count_docs = count_chunker.ProcessDocuments(item_struct[0], max_workers=2)\n",
        "\n",
        "# TypeError: ProcessDocuments(): incompatible function arguments. The following argument types are supported:\n",
        "#     1. (self: purecpp_chunks_clean.purecpp_chunks_clean.ChunkCount, items: list[RAGLibrary::LoaderDataStruct], max_workers: int = 4) -> list[RAGLibrary::Document]\n",
        "\n",
        "# Invoked with: <purecpp_chunks_clean.purecpp_chunks_clean.ChunkCount object at 0x7f8b55d10b30>, <purecpp_libs.purecpp_libs.LoaderDataStruct object at 0x7f8b75d467f0>; kwargs: max_workers=2\n",
        "\n",
        "count_docs2 = count_chunker.ProcessDocuments(item_struct, max_workers=2) # tem q ser a lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_29mUNwnBVU8",
        "outputId": "c48749d4-6b4e-4bed-b697-c2c95b98763c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChunkCount from '1984': documents.size=6914\n"
          ]
        }
      ],
      "source": [
        "print(f\"ChunkCount from '{item_struct[0].metadata['fileIdentifier']}': documents.size={len(count_docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RV2_9DJDBVU8"
      },
      "outputs": [],
      "source": [
        "# default_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUuJZVCbBVU8",
        "outputId": "81a7cc17-567a-4de5-d756-a73e3f84286a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SplitText] Gerei 3 pedaços. Primeiro pedaço:\n",
            "   Este é um texto de exemplo.\n",
            "Ele será unido e fat\n"
          ]
        }
      ],
      "source": [
        "# 4) USANDO ALGUMAS FUNÇÕES DE CHUNKCOMMONS MANUALMENTE\n",
        "#    Exemplo:  (a) Dividir manualmente um texto e (b) Gerar embeddings via OpenAI\n",
        "#    (c) Normalizar e exibir a embedding\n",
        "\n",
        "# (a) SplitText manual\n",
        "text_example = [\"Este é um texto de exemplo.\", \"Ele será unido e fatiado em 50 chars com 10 de overlap.\"]\n",
        "splitted = cc.SplitText(text_example, overlap=10, chunk_size=50)\n",
        "print(f\"[SplitText] Gerei {len(splitted)} pedaços. Primeiro pedaço:\\n   {splitted[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpNfKbKLBVU8",
        "outputId": "8ab5eac7-c557-44c3-e327-cd8abb63fed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Não foi possível gerar embeddings com OpenAI (talvez sem chave válida): {\"code\":\"invalid_api_key\",\"message\":\"Incorrect API key provided: sk-proj-********************************************************************************************************************************************************SkkA. You can find your API key at https://platform.openai.com/account/api-keys.\",\"param\":null,\"type\":\"invalid_request_error\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (b) Gerar embeddings via OpenAI (necessita openai_api_key)\n",
        "\n",
        "try:\n",
        "    openai_emb = cc.EmbeddingOpeanAI(\n",
        "        [\"Este é um teste para OpenAI Embeddings\"],\n",
        "        API_KEY,\n",
        "    )\n",
        "    print(f\"[EmbeddingOpeanAI] Embedding gerada com dim={len(openai_emb[0])} para a frase:\")\n",
        "    print(\"   'Este é um teste para OpenAI Embeddings'\")\n",
        "\n",
        "    # (c) Normalizar a primeira embedding\n",
        "    cc.NormalizeEmbeddings(openai_emb[0])\n",
        "    print(f\"Depois da normalização, norma aprox. = ? (Podemos checar manualmente se está ~1)\\n\")\n",
        "except Exception as e:\n",
        "    print(\"Não foi possível gerar embeddings com OpenAI (talvez sem chave válida):\", e)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW6M6aQLBVU8"
      },
      "outputs": [],
      "source": [
        "# 5) USANDO ChunkQuery (exemplo de pergunta com embeddings HuggingFace)\n",
        "#    chunk_size=200, overlap=50, se \"HuggingFace\" não tiver local .onnx, seria outro.\n",
        "query_chunker = cc.ChunkQuery(\n",
        "                  chunk_size=200,\n",
        "                  overlap=50,\n",
        "                  embedding_model=cc.EmbeddingModel.HuggingFace,  # ou cc.EmbeddingModel.OpenAI\n",
        "                  openai_api_key = API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6dnPtesCBVU8",
        "outputId": "2aa15d1c-4638-4e3a-9efb-116a193027d5"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Load model from models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed:Load model models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed. File doesn't exist",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-9a82012f8058>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Gera embedding da query internamente e filtra chunks relevantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"O que diz o doc sobre impactos ambientais?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m relevant_docs = query_chunker.ProcessDocuments(\n\u001b[0m\u001b[1;32m      4\u001b[0m                   \u001b[0mitem_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mquery_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Load model from models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed:Load model models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed. File doesn't exist"
          ]
        }
      ],
      "source": [
        "# Gera embedding da query internamente e filtra chunks relevantes\n",
        "query_text = \"O que diz o doc sobre impactos ambientais?\"\n",
        "relevant_docs = query_chunker.ProcessDocuments(\n",
        "                  item_struct,\n",
        "                  query_text,\n",
        "                  similarity_threshold=0.7,\n",
        "                  max_workers=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "p3FJEAkoBVU9",
        "outputId": "a2884005-00de-433b-c6ac-5017ba22ede2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'relevant_docs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-fd2af90ea361>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[ChunkQuery] A query '{query_text}' retornou {len(relevant_docs)} chunks relevantes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'relevant_docs' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"[ChunkQuery] A query '{query_text}' retornou {len(relevant_docs)} chunks relevantes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wwATI5hkBVU9",
        "outputId": "b609ddab-19ae-41ad-b0bf-b0fe8aa392a7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'relevant_docs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-d34c5ef1c762>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exemplo de chunk relevante:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   METADATA:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   CHUNK (trecho):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'relevant_docs' is not defined"
          ]
        }
      ],
      "source": [
        "if relevant_docs:\n",
        "    print(\"Exemplo de chunk relevante:\")\n",
        "    print(\"   METADATA:\", relevant_docs[0].metadata)\n",
        "    print(\"   CHUNK (trecho):\", relevant_docs[0].page_content[:100], \"...\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3x20AwraBVU9",
        "outputId": "ed5ff1b8-f27e-42be-bc97-d92d824459f7"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Load model from models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed:Load model models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed. File doesn't exist",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-2fcfa24b3a1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mopenai_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ou use: os.getenv(\"OPENAI_API_KEY\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msim_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_chunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessSingleDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_struct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[ChunkSimilarity] Em docA.pdf (supondo items[0]), gerou {len(sim_docs)} chunks.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Eles estão ordenados de acordo com a soma de similaridades com os demais:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Load model from models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed:Load model models/sentence-transformers/all-MiniLM-L6-v2/model.onnx failed. File doesn't exist"
          ]
        }
      ],
      "source": [
        "# 6) USANDO ChunkSimilarity (auto-similarity dentro do doc)\n",
        "#    Pegamos só o primeiro item, como exemplo\n",
        "if items:\n",
        "    sim_chunker = cc.ChunkSimilarity(\n",
        "        chunk_size=150,\n",
        "        overlap=30,\n",
        "        embedding_model=cc.EmbeddingModel.HuggingFace,\n",
        "        openai_api_key = API_KEY,  # ou use: os.getenv(\"OPENAI_API_KEY\")\n",
        "    )\n",
        "    sim_docs = sim_chunker.ProcessSingleDocument(item_struct[0])\n",
        "    print(f\"[ChunkSimilarity] Em docA.pdf (supondo items[0]), gerou {len(sim_docs)} chunks.\")\n",
        "    print(\"Eles estão ordenados de acordo com a soma de similaridades com os demais:\")\n",
        "    if sim_docs:\n",
        "        print(f\"   Primeiro chunk reordenado: {sim_docs[0].page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pvjnKx7BVU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e1w9rbnBVU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGpWCu2oBVU9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
